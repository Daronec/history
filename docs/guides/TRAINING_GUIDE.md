# üéì –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–±—É—á–µ–Ω–∏—é –ò–ò –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏

## üìö –û–±–∑–æ—Ä

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–∫–∞–∂–µ—Ç –≤–∞–º, –∫–∞–∫ –æ–±—É—á–∞—Ç—å –ò–ò –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤.

## üéØ –¢–∏–ø—ã –æ–±—É—á–µ–Ω–∏—è

### 1. **Fine-tuning (–î–æ–æ–±—É—á–µ–Ω–∏–µ)**
- –ë–µ—Ä–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (DistilGPT2, GPT-2, etc.)
- –û–±—É—á–∞–µ–º –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –ú–æ–¥–µ–ª—å –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç

### 2. **–û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è**
- –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –Ω—É–ª—è
- –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –∏ –≤—Ä–µ–º–µ–Ω–∏
- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
ls data/raw/
# –î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ñ–∞–π–ª sample_history_data.json
```

### –®–∞–≥ 2: –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```bash
# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
venv\Scripts\activate

# –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö (1 —ç–ø–æ—Ö–∞)
python src/train_model.py --data sample --task generation --epochs 1 --model distilgpt2
```

### –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```bash
# –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
python -c "
from src.models.history_ai import HistoryAIModel
ai = HistoryAIModel()
ai.load_trained_model('./models/history_ai_trained')
result = ai.generate_text('–í 1812 –≥–æ–¥—É –ø—Ä–æ–∏–∑–æ—à–ª–æ:', max_length=100)
print(result)
"
```

## üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `data/raw/my_history_data.json`:

```json
[
  {
    "text": "–í–∞—à –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç –∑–¥–µ—Å—å",
    "category": "–≤–æ–π–Ω–∞",
    "period": "XIX –≤–µ–∫",
    "importance": "–≤—ã—Å–æ–∫–∞—è"
  },
  {
    "text": "–ï—â–µ –æ–¥–∏–Ω –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Ñ–∞–∫—Ç",
    "category": "—Ä–µ—Ñ–æ—Ä–º—ã", 
    "period": "XVIII –≤–µ–∫",
    "importance": "—Å—Ä–µ–¥–Ω—è—è"
  }
]
```

### –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–∞–Ω–Ω—ã—Ö

- **–≤–æ–π–Ω–∞** - –≤–æ–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã
- **—Ä–µ—Ñ–æ—Ä–º—ã** - –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ—Ñ–æ—Ä–º—ã
- **–ø–æ–ª–∏—Ç–∏–∫–∞** - –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è
- **—Ä–µ–ª–∏–≥–∏—è** - —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
- **—Ä–µ–≤–æ–ª—é—Ü–∏—è** - —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
- **–∫—É–ª—å—Ç—É—Ä–∞** - –∫—É–ª—å—Ç—É—Ä–Ω—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

```bash
python src/train_model.py \
  --data data/raw/my_data.json \    # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
  --task generation \               # –¢–∏–ø –∑–∞–¥–∞—á–∏
  --epochs 3 \                     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
  --model distilgpt2               # –ú–æ–¥–µ–ª—å
```

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

- `--epochs` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (1-10)
- `--model` - –º–æ–¥–µ–ª—å (distilgpt2, gpt2, microsoft/DialoGPT-medium)
- `--task` - —Ç–∏–ø –∑–∞–¥–∞—á–∏ (generation, classification)

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –∫–æ–¥–µ

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `src/models/history_ai.py`:

```python
training_args = TrainingArguments(
    output_dir="./models/history_ai_trained",
    num_train_epochs=num_epochs,           # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
    per_device_train_batch_size=4,         # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    per_device_eval_batch_size=4,          # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    warmup_steps=500,                      # –®–∞–≥–∏ —Ä–∞–∑–æ–≥—Ä–µ–≤–∞
    weight_decay=0.01,                     # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    learning_rate=5e-5,                    # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    logging_dir="./logs",                  # –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤
    logging_steps=10,                      # –ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    save_steps=1000,                       # –ß–∞—Å—Ç–æ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    save_total_limit=2,                    # –ú–∞–∫—Å–∏–º—É–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π
)
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è

```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
tail -f logs/trainer_state.json

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ TensorBoard
tensorboard --logdir logs
```

### –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

- **Loss** - –ø–æ—Ç–µ—Ä–∏ –º–æ–¥–µ–ª–∏ (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
- **Perplexity** - —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
- **BLEU Score** - –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

## üéÆ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏

```bash
# –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª data/raw/russian_history.json
python src/train_model.py --data data/raw/russian_history.json --epochs 2
```

### –ü—Ä–∏–º–µ—Ä 2: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ

```bash
# –î–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –æ XIX –≤–µ–∫–µ
python src/train_model.py --data data/raw/19th_century.json --epochs 3
```

### –ü—Ä–∏–º–µ—Ä 3: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π

```bash
# –û–±—É—á–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
python src/train_model.py --data sample --task classification --epochs 2
```

## üö® –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ü—Ä–æ–±–ª–µ–º–∞: "Out of memory"

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
per_device_train_batch_size=2  # –≤–º–µ—Å—Ç–æ 4
```

### –ü—Ä–æ–±–ª–µ–º–∞: "Model not learning"

**–†–µ—à–µ–Ω–∏–µ:**
- –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
- –£–º–µ–Ω—å—à–∏—Ç–µ learning_rate

### –ü—Ä–æ–±–ª–µ–º–∞: "Poor text generation"

**–†–µ—à–µ–Ω–∏–µ:**
- –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
- –£–≤–µ–ª–∏—á—å—Ç–µ max_length –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ temperature

## üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞

```python
from src.models.history_ai import HistoryAIModel

ai = HistoryAIModel()
ai.load_trained_model('./models/history_ai_trained')

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–∞—Ö
test_prompts = [
    "–í 1812 –≥–æ–¥—É –ø—Ä–æ–∏–∑–æ—à–ª–æ:",
    "–ü–µ—Ç—Ä I –∏–∑–≤–µ—Å—Ç–µ–Ω —Ç–µ–º, —á—Ç–æ:",
    "–†–µ–≤–æ–ª—é—Ü–∏—è 1917 –≥–æ–¥–∞:"
]

for prompt in test_prompts:
    result = ai.generate_text(prompt, max_length=100)
    print(f"–ü—Ä–æ–º–ø—Ç: {prompt}")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    print("-" * 50)
```

### –†—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

1. **–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å** - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Ç–µ–º–µ?
2. **–§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ª–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∫—Ç—ã?
3. **–°–≤—è–∑–Ω–æ—Å—Ç—å** - –ª–æ–≥–∏—á–Ω–æ –ª–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω —Ç–µ–∫—Å—Ç?
4. **–°—Ç–∏–ª—å** - –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —Å—Ç–∏–ª—å –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞?

## üéØ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏

### 1. Transfer Learning

```python
# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
ai = HistoryAIModel("microsoft/DialoGPT-medium")
ai.load_model("generation")

# –î–æ–æ–±—É—á–∞–µ–º –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
ai.train(historical_dataset, num_epochs=2)
```

### 2. Data Augmentation

```python
# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
augmented_texts = []
for text in original_texts:
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏
    augmented_texts.append(text)
    augmented_texts.append(text.replace("–≥–æ–¥—É", "–≥."))
    augmented_texts.append(text.replace("–ø—Ä–æ–∏–∑–æ—à–ª–æ", "—Å–ª—É—á–∏–ª–æ—Å—å"))
```

### 3. Multi-task Learning

```python
# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
tasks = ["generation", "classification", "summarization"]
for task in tasks:
    ai.load_model(task)
    ai.train(task_datasets[task])
```

## üìö –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö:
1. –ù–∞—á–Ω–∏—Ç–µ —Å –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö (1-2)
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ (DistilGPT2)
3. –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–æ–º–ø—Ç–∞—Ö

### –î–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö:
1. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
3. –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏

### –û–±—â–∏–µ —Å–æ–≤–µ—Ç—ã:
- –í—Å–µ–≥–¥–∞ –¥–µ–ª–∞–π—Ç–µ –±—ç–∫–∞–ø –¥–∞–Ω–Ω—ã—Ö
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

## üéâ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–û–±—É—á–µ–Ω–∏–µ –ò–ò –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ - —ç—Ç–æ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å. –ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–ª—É—á—à–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

**–£–¥–∞—á–∏ –≤ –∏–∑—É—á–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Å –ò–ò! üèõÔ∏èü§ñ**
